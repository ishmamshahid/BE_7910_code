{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:\\\\LSU\\\\Sp_2025\\\\BE7910\\\\titanic\\\\train.csv\")\n",
    "test = pd.read_csv(\"D:\\\\LSU\\\\Sp_2025\\\\BE7910\\\\titanic\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"FamilySize\"] = train[\"Parch\"] + train[\"SibSp\"]\n",
    "test[\"FamilySize\"] = test[\"Parch\"] + test[\"SibSp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[['Pclass', 'Sex', 'Age', 'FamilySize', 'Fare', 'Embarked']]\n",
    "y = train[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test[['Pclass', 'Sex', 'Age', 'FamilySize', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass          0\n",
       "Sex             0\n",
       "Age           177\n",
       "FamilySize      0\n",
       "Fare            0\n",
       "Embarked        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Sex            0\n",
       "Age           86\n",
       "FamilySize     0\n",
       "Fare           1\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass          0\n",
       "Age           177\n",
       "FamilySize      0\n",
       "Fare            0\n",
       "Sex_female      0\n",
       "Sex_male        0\n",
       "Embarked_C      0\n",
       "Embarked_Q      0\n",
       "Embarked_S      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoded_df = encoder.fit_transform(x[['Sex', 'Embarked']])\n",
    "\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "encoded_df = pd.DataFrame(encoded_df.toarray(), columns=feature_names)\n",
    "\n",
    "# Drop the last encoded column to avoid dummy variable trap (optional)\n",
    "encoded_df = encoded_df.drop(feature_names[-1], axis=1)\n",
    "\n",
    "# Integrate back into X\n",
    "x1 = x.drop(['Sex', 'Embarked'], axis=1)\n",
    "x1 = pd.concat([x1, encoded_df], axis=1)\n",
    "x1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Age           86\n",
       "FamilySize     0\n",
       "Fare           1\n",
       "Sex_female     0\n",
       "Sex_male       0\n",
       "Embarked_C     0\n",
       "Embarked_Q     0\n",
       "Embarked_S     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df_test = encoder.transform(x_test[['Sex', 'Embarked']])\n",
    "\n",
    "encoded_df_test = pd.DataFrame(encoded_df_test.toarray(), columns=feature_names)\n",
    "\n",
    "# Drop the last encoded column to avoid dummy variable trap (optional)\n",
    "encoded_df_test = encoded_df_test.drop(feature_names[-1], axis=1)\n",
    "\n",
    "# Integrate back into X\n",
    "x1_test = x_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "x1_test = pd.concat([x1_test, encoded_df_test], axis=1)\n",
    "x1_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "FamilySize    0\n",
       "Fare          0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "Age           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "age_imputed = imputer.fit_transform(pd.DataFrame(x1['Age']))\n",
    "\n",
    "imputed_df = pd.DataFrame(age_imputed, columns=[\"Age\"])\n",
    "\n",
    "# Replace original Age column\n",
    "x1 = x1.drop(['Age'], axis=1)\n",
    "x1 = pd.concat([x1, imputed_df], axis=1)\n",
    "x1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "FamilySize    0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "Age           0\n",
       "Fare          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_imputed_test = imputer.transform(pd.DataFrame(x1_test['Age']))\n",
    "\n",
    "fare_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "fare_imputed = fare_imputer.fit_transform(pd.DataFrame(x1['Fare']))\n",
    "fare_imputed_test = fare_imputer.transform(pd.DataFrame(x1_test['Fare']))\n",
    "\n",
    "imputed_df_age_test = pd.DataFrame(age_imputed_test, columns=[\"Age\"])\n",
    "imputed_df_fare_test = pd.DataFrame(fare_imputed_test, columns=[\"Fare\"])\n",
    "\n",
    "# Replace original Age column\n",
    "x1_test = x1_test.drop(['Age'], axis=1)\n",
    "x1_test = x1_test.drop(['Fare'], axis=1)\n",
    "x1_test = pd.concat([x1_test, imputed_df_age_test, imputed_df_fare_test], axis=1)\n",
    "x1_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x1)\n",
    "\n",
    "x_scaled = pd.DataFrame(x_scaled, columns=x1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test = x1_test[x1.columns]\n",
    "\n",
    "x_test_scaled = scaler.transform(x1_test)\n",
    "\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x1_test.columns)\n",
    "\n",
    "x_test_scaled = x_test_scaled[x_scaled.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "FamilySize    0\n",
       "Fare          0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "Age           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = RandomForestClassifier()\n",
    "#model.fit(x_scaled, y.squeeze())\n",
    "\n",
    "#y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Score: 0.8282844768062269\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "# GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,             # 5-fold cross-validation\n",
    "    n_jobs=-1     # use all available CPU cores\n",
    ")\n",
    "# Fit on training data\n",
    "grid_search.fit(x_scaled, y.squeeze())\n",
    "# Inspect best hyperparams and best score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to predict on test data\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_test_pred = best_rf.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"D:\\\\LSU\\\\Sp_2025\\\\BE7910\\\\titanic\\\\pred_RF_classifier_HP_tuning.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
